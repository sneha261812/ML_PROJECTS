{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7309e183-858d-43f2-bfcb-8345e61dfb64",
   "metadata": {},
   "source": [
    "***LOGISTIC REGRESSION USING USING DIABETES DATASET***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4234b-9483-4459-97e3-3c4b6f60540b",
   "metadata": {},
   "source": [
    "**using imports and packages/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a51b79a-acc5-4e5b-90e5-dd9959c74f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[36 13]\n",
      " [11 29]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75        49\n",
      "           1       0.69      0.72      0.71        40\n",
      "\n",
      "    accuracy                           0.73        89\n",
      "   macro avg       0.73      0.73      0.73        89\n",
      "weighted avg       0.73      0.73      0.73        89\n",
      "\n",
      "Accuracy Score: 0.7303370786516854\n",
      "\n",
      "Sample prediction (0 = non-diabetic, 1 = diabetic): 0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the diabetes dataset (Note: this is actually a regression dataset)\n",
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y_continuous = data.target\n",
    "\n",
    "# Convert regression target into binary classification:\n",
    "# Let's say target > 140 is considered \"diabetic\" (1), else \"non-diabetic\" (0)\n",
    "y = (y_continuous > 140).astype(int)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Output results\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Example prediction\n",
    "sample = X_test_scaled[0].reshape(1, -1)\n",
    "sample_pred = model.predict(sample)\n",
    "print(\"\\nSample prediction (0 = non-diabetic, 1 = diabetic):\", sample_pred[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e0f7d-e308-471b-9355-69503e22af05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38397db9-a89e-40f1-a435-a3a15be0cdda",
   "metadata": {},
   "source": [
    "#without imports an packages#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf9d6af-a16e-4d7c-9294-7833ba57ae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 : Cost = 10.013553484350554\n",
      "Iteration 100 : Cost = 4.6643031895251\n",
      "Iteration 200 : Cost = 11.387249177472746\n",
      "Iteration 300 : Cost = 11.788484764054123\n",
      "Iteration 400 : Cost = 4.0988706920409115\n",
      "Iteration 500 : Cost = 7.440055101223103\n",
      "Iteration 600 : Cost = 11.652079758855402\n",
      "Iteration 700 : Cost = 11.453753870853411\n",
      "Iteration 800 : Cost = 9.27142466023239\n",
      "Iteration 900 : Cost = 21.8135569631101\n",
      "Accuracy: 0.6471\n",
      "Precision: 0.4571\n",
      "Recall: 0.0597\n",
      "F1 Score: 0.1056\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    if z < -100:\n",
    "        return 0  # Prevent underflow\n",
    "    if z > 100:\n",
    "        return 1  # Prevent overflow\n",
    "    return 1 / (1 + (2.71828 ** -z))\n",
    "\n",
    "# Cost function (Log Loss)\n",
    "def compute_cost(X, y, weights):\n",
    "    m = len(y)\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "        z = sum(X[i][j] * weights[j] for j in range(len(weights)))\n",
    "        pred = sigmoid(z)\n",
    "        # Avoid log(0) by clipping prediction values\n",
    "        pred = max(min(pred, 1 - 1e-15), 1e-15)\n",
    "        cost += -(y[i] * math.log(pred) + (1 - y[i]) * math.log(1 - pred))\n",
    "    return cost / m\n",
    "\n",
    "# Gradient Descent\n",
    "def gradient_descent(X, y, weights, learning_rate, iterations):\n",
    "    m = len(y)\n",
    "    for it in range(iterations):\n",
    "        gradients = [0] * len(weights)\n",
    "        for i in range(m):\n",
    "            z = sum(X[i][j] * weights[j] for j in range(len(weights)))\n",
    "            pred = sigmoid(z)\n",
    "            error = pred - y[i]\n",
    "            for j in range(len(weights)):\n",
    "                gradients[j] += error * X[i][j]\n",
    "        for j in range(len(weights)):\n",
    "            weights[j] -= learning_rate * gradients[j] / m\n",
    "        if it % 100 == 0:\n",
    "            print(\"Iteration\", it, \": Cost =\", compute_cost(X, y, weights))\n",
    "    return weights\n",
    "\n",
    "# Prediction function\n",
    "def predict(X, weights):\n",
    "    predictions = []\n",
    "    for i in range(len(X)):\n",
    "        z = sum(X[i][j] * weights[j] for j in range(len(weights)))\n",
    "        prob = sigmoid(z)\n",
    "        predictions.append(1 if prob >= 0.5 else 0)\n",
    "    return predictions\n",
    "\n",
    "# Evaluation metrics\n",
    "def evaluate(y_true, y_pred):\n",
    "    tp = sum(1 for i in range(len(y_true)) if y_true[i] == 1 and y_pred[i] == 1)\n",
    "    tn = sum(1 for i in range(len(y_true)) if y_true[i] == 0 and y_pred[i] == 0)\n",
    "    fp = sum(1 for i in range(len(y_true)) if y_true[i] == 0 and y_pred[i] == 1)\n",
    "    fn = sum(1 for i in range(len(y_true)) if y_true[i] == 1 and y_pred[i] == 0)\n",
    "\n",
    "    accuracy = (tp + tn) / len(y_true)\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "    print(\"Accuracy:\", round(accuracy, 4))\n",
    "    print(\"Precision:\", round(precision, 4))\n",
    "    print(\"Recall:\", round(recall, 4))\n",
    "    print(\"F1 Score:\", round(f1, 4))\n",
    "\n",
    "# Load dataset\n",
    "def load_data(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()[1:]  # Skip header\n",
    "            data = []\n",
    "            for line in lines:\n",
    "                values = line.strip().split(',')\n",
    "                try:\n",
    "                    row = [float(v) for v in values]\n",
    "                    data.append(row)\n",
    "                except ValueError:\n",
    "                    print(\"Warning: Skipping invalid row -\", line.strip())\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found.\")\n",
    "        return []\n",
    "\n",
    "# Main execution\n",
    "import math\n",
    "\n",
    "filename = 'diabetes.csv'  # Path to your dataset\n",
    "data = load_data(filename)\n",
    "\n",
    "if data:\n",
    "    # Separate features and labels\n",
    "    X = [[1] + row[:-1] for row in data]  # Add bias (intercept term) as 1\n",
    "    y = [int(row[-1]) for row in data]   # Class labels (0 or 1)\n",
    "\n",
    "    weights = [0] * len(X[0])  # Initialize weights to zero\n",
    "\n",
    "    # Train model\n",
    "    weights = gradient_descent(X, y, weights, learning_rate=0.01, iterations=1000)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = predict(X, weights)\n",
    "\n",
    "    # Evaluate\n",
    "    evaluate(y, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352959bf-8b3e-412f-9d5b-7c0544ac72ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:com]",
   "language": "python",
   "name": "conda-env-com-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
