{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82b3299-8f87-41a3-b404-54cf16232ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: setosa\n"
     ]
    }
   ],
   "source": [
    "# Na√Øve Bayes Classifier for Iris Dataset (No Libraries)\n",
    "\n",
    "# Load dataset manually\n",
    "def load_dataset(filename):\n",
    "    dataset = []\n",
    "    with open(filename, \"r\") as file:\n",
    "        lines = file.readlines()[1:]  # Skip header\n",
    "        for line in lines:\n",
    "            dataset.append(line.strip().split(\",\"))\n",
    "    return dataset\n",
    "\n",
    "# Load the iris dataset\n",
    "data = load_dataset(\"iris.csv\")  # Make sure iris.csv is in the same directory\n",
    "\n",
    "# Step 1: Separate by class\n",
    "class_counts = {}\n",
    "total_samples = len(data)\n",
    "\n",
    "for row in data:\n",
    "    label = row[-1]  # Class is the last column\n",
    "    class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "# Step 2: Compute prior probabilities\n",
    "priors = {cls: count / total_samples for cls, count in class_counts.items()}\n",
    "\n",
    "# Step 3: Compute likelihood probabilities (discretized approach for simplicity)\n",
    "feature_probs = {}\n",
    "\n",
    "for cls in class_counts:\n",
    "    feature_probs[cls] = {i: {} for i in range(len(data[0]) - 1)}  # Exclude class label\n",
    "    class_samples = [row for row in data if row[-1] == cls]\n",
    "\n",
    "    for feature_index in range(len(data[0]) - 1):\n",
    "        feature_values = [row[feature_index] for row in class_samples]\n",
    "        total_class_samples = len(class_samples)\n",
    "\n",
    "        for value in set(feature_values):\n",
    "            feature_probs[cls][feature_index][value] = feature_values.count(value) / total_class_samples\n",
    "\n",
    "# Step 4: Prediction function\n",
    "def predict(features):\n",
    "    probabilities = {}\n",
    "    for cls in class_counts:\n",
    "        probabilities[cls] = priors[cls]\n",
    "        for feature_index in range(len(features)):\n",
    "            feature_value = features[feature_index]\n",
    "            if feature_value in feature_probs[cls][feature_index]:\n",
    "                probabilities[cls] *= feature_probs[cls][feature_index][feature_value]\n",
    "            else:\n",
    "                probabilities[cls] *= 1e-6  # Smoothing for unseen values\n",
    "    return max(probabilities, key=probabilities.get)\n",
    "\n",
    "# Step 5: Test the model with a new flower\n",
    "new_sample = [\"5.1\", \"3.5\", \"1.4\", \"0.2\"]  # Example flower features\n",
    "prediction = predict(new_sample)\n",
    "print(f\"Predicted Class: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cdfa4d-1471-4ebb-bad5-54a7086c0ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:com]",
   "language": "python",
   "name": "conda-env-com-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
